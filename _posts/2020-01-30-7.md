---
title: Models and Algorithms (2)
author: Brett Petch
date: 2020-01-30 09:30:00
layout: category-post
categories: 
    - week-4
    - Lecture
---

Today, we're going to be looking at this through Kathy O'Neil's Weapons of math destruction. She talks about this in how to determine a teacher is a quality. Determining approach, benefit to teachers, etc. To measure this, the approach was taken as follows:

- 35% classroom observations
- 15% collaboration and contributions to the school community outside of teaching.
- 50% value added measurement of student improvement. (what value added did the teacher provide?)

Why might this not be the best way?
- could be a good class

Today, we wil be looking at 

# How do algorithms become problematic?
While researchers may be trying to improve things, faulty logic, etc.
Although algorithms appear to be fair and balanced, they are not neutral or free from bias. They are the product of society, and they carry within the ideals and assumptions of their production. 

Algorithms: the use of models and measurements in order ot bring about desired outcomes. We make these different ideas and assumptions based on this. When we're looking at alot of this material, we're trying to determine some kind of subjective question. We will often use proxy questions instead, as the metric is often intangible. 

This is something that Google tries to do: What are the best websites on the internet? instead, it will analyse the ones that are most linked. We are essentially turning a subjective question into a statistical measurement.

O'Neil: when algorithms are trusted inherrently ,reliable or overstate their measurements, they become Weapons of Math Destructon -- problematic cechnologies reproduce...

## Recidivism Measurments
- Algorithms use questions to scores measure recidivism scores that will measure the probability someone will reoffend if released from prison.
- Studies show that they unfairly target non-whites.

### How Do We Measure the Results?
Class: Psychological evaluation to understand, repeated offense, crime committed (violent, trespassing, etc.)

#### Questions
- "was one of your parents ever sent to jail or prison?"
- "How many of your frineds / acquaintances are taking drugs illegally?"
- "How often did you get in fights while at school?"
- "When was teh first time you were involved with the police?"

#### Yes / No
- "A hungry person has a right to steal"
- "If people make me angry or lose my temper, I can be dangerous"

#### Class responses to questions:
The questions are trying to ensure racial minorities... The ideas of forcing drugs into communities, etc. Underfunding schools to ensure fights, etc.

The overall reliability of the algorithms were inaccurate. These proxy questions to determine something...

## So when do algorithms become weapons of math destruction?
I don't see everything they are doing as inherrantly wrong. One of the things she highlights is the opacity, or how clear something is. If algorithms are opaque, we aren't sure how the data is being measured. Logically, I don't think it would be all that wrong to steal if you are starving. So, are these things clear or opaque? Algorithms often act as black boxes. 

Algorithms require the use of feedback to correct and refine the data. Every set of data has outliers. New data needs to have a correction to adjust itself.

2. Does the model work against the individuals interests? does it damage their life?
How accurate are hte proxies we use to make the measurement?


Scalability: What is the size of the dataset? Is there enough information to generalize and make assumptions? For example, can we make an assessment based on one year of teaching?

### How Much Data?

|Census                                    |Sample                                       |
|:-----------------------------------------|:--------------------------------------------|
| survey of every member of the population.| A Sample is a subset of a larger population |
| | A method of learning about a population without the time and expense of a census     |

O'Neil: When data is skewed, it ends up reproducing social inequities and resulting in biased results. Looking at data, can we determine if child abuse is predicted. Most of these people are of a lower class to use that place (a social worker) because they cannot afford different counciling. People feel like they are being targeted by algorithms. 

