---
title: Google 1 - The Google Search Engine (1)
author: Brett Petch
date: 2020-01-14 09:30:00
layout: category-post
categories:
    - week-2
    - Lecture
---
# Google 1: The Google Search Engine

## Today:
- How do search engines work
- Thursday: Google's ranking algorithm and "trust bias"; implications of organization, etc.

## Birth of the WWW
- 1990: Tim Berners-lee develops World Wide Web: afraid of communications being downed, looking for comms platform. 
- Created HTML, HTTP, etc for the WWW browser: Mosaic (first point and click browser)

## Home Computing
Created a new way to access information, accessible to most home users. The information on the early internet was not written in a clear way. At the beginning of the internet, it was very messy and untrustworthy. The question soon became trust. In this context, we needed to find a way to think about accessing information, how we find reliable sources.
Many times, you would not be able to find information, for instance healthcare. How do we find a way to navigate "trustworthy" information
- 1990's: riseo f home computing
    - Via internet, computers can contact each other
    - Public files on computers can be read by remote user
- Large increase in access to information online
    - Much of it created by "users" rather than traditional "writers and publishers"
    - enable user-driven content, eg. blogging

## Search Engines
Beginning with Alta Vista and WebCrawler, you needed to look at page after page of results. They were often irrelevant to you. Google then began to emerge; they thought there was a better way to organize information better than other search engines using a ranking system.
Google heavily relied on Library Information Sciences, they thought they could sell this to existing search engines. Yahoo, AV thought it worked too well, as they got ad revenue each search.
Thought they would lose money because people would be using as an intermediary. By 1998, Google was released.
Google has massive comprehension, and has catalogued a large portion of the web. A few years ago, it had catalogued 25x the amount of the average search engine. It also has higher accuracy in its results. Google seems to anticipate exactly what we are thinking. When we search news, it knows exactly how it should be catagorized. It also knows "what movie is with the sparkly vampire" -> Twilight.
Life before Google: you weren't able to think about something you didn't know about. It changed the way we think about access to information.

- 1994: First genuine search engines:
    - Alta Vista, Web Crawler
- 1998: Google: developed by Larry Page and Sergey Brin
    - PhD students
- Silva Vaidhyanathan: Google has redefined the way we access information:
    - Comprehension of its cataloguing of the web and abundance of its results.
    - Accuracy of results.
- Question: How many times per day (on average) do you think you use Google - both in terms of its search engine and all its products (eg. gMail, docs, etc.)

## Some important distinctions
- Web directory: a listing of websites orgnaized into an interconnected list of categories;
    - maintained by human indexers
    - often uses a search engine to locate materials in the direcotry

Examples: [Sources](https://www.sources.com)

This is a site for journalists and other professionals. This is different from a search engine, as it's community. If you were a journalist and looking for information an a specific topic, looking at media studies, you would be able find spokespeople to talk about info. It's not necessarily just about articles, but often contains phone numbers, etc.

- Web search engine: computer programs which automatically copy locate and index websites by accessing hyperlinks
    - largely automated;
    - [Google](https://google.ca)
    - [Bing](https://bing.com)
- some used to be a cross; Alta Vista was considered to be one

## How do Search Engines Work?
- see [How Search Works](https://www.youtube.com/watch?v=BNHR6IQJGZs) on YouTube.

## Parts of a Search Engine
We're going to look into different parts. You can't scan every part of the web instantly, instead it's an index that is being searched. The crawler is a component that will crawl webpages, links, etc. There is also the index, where data is stored. And the interface, where you will find the searchbar. Finally, there is a ranking algorithm that organizes the data in the index, later shown in the interface.

## The Crawler
The goal of a crawler is to scan the entire web. The idea is to go from page to page. One page leads to another, which leads to another. It's following page to page across the internet. It validates URLs, detects what is new. There is a specific sequence that a crawler will follow. The standard sequence: Starts with a 'seed' URL or set of seed URLs, then places them in a processing sequenc,e then takes a url from the sequence, open the page and download it. It will then parse it for web links and add those links to the URL sequence, eventually repeating. 
- A computer program which automatically opens and copies web pages:
    - Begins with an inital set of URLS
    - Follows hyperlinks to other Web pages and downloads them.

### Crawling Sequence:
- Start iwth a seed URL
- Place in processing sequence
- Take a URL from the sequence
- Open the page and download it
- Parse it for web links and add those links to URL sequence
- Repeat

#### Robot Orders
There are certain rules that a crawler will follow. For instance, robot.txt is a file in the ehader of the webpage that orders the crawler not ot crawl or index specific sub-pages (see Western example)
- Robots meta tag: a tag in the header of a webpage which instructs the crawler how to treat the content.

| Command | Meaning |
|:--------|-----------------------------|
| All     | No restrictions             |

#### Problems
There are sometimes loops, where it will scan a page over and over again. There are issues with coverage, where websites are not crawled as much. Buisnesses will argue that their content is not being crawled properly. Additionally, frequency is higher than that of something that is static.

## The Index
The index is a gigantic database which stores the pages downloaded from the search engine, encoded in a way that enables easy retrieval. They are typically organized by different categories and terms which store the data similar to a search engine, allowing for easy retreival. Google uses enouhg energy to power 200,000 american homes. There is a real material underpinning, specifically on human labour, etc. What is the labour on Big Data? There are people that will look at information to see if it is acceptable for posting.
- A gigantic search database which stores the pages downloaded from the search engine, encoded in a way that enables easy retrieval
- Frequently mirrored and distributed over massive collections of machines linked together, called server farms.

### Welcome to the wolrd's smallest search engine:
1. It is going to take it into tokens, chunks of text that indexing processor will consider words. Each token will consider words. Each token is linked with its document.
2. Alphabetize the list (organize to keep seperate documents)
3. Refine the index throuhg text processing: stopping - removal of words that are considered too common for useful retreval.
    - stemming: combining different word forms because of plurals or short forms
    
- Ngram viewer: understanding natural language, anticipate next words.

Term Weighting
- location

### Updating the Index:
- Index needs to be updated regularly
    1. New pages found by the crawler
    2. Updates to a webpage (some update more than others)
- Doing website checks: common links, news, etc. Bing also has recent news, pop-cultture, as well as yahoo. derrived from alta-vista.

## Question:
- Why do you think that Google's inteterface has been so successful, even thouhg other search engines have gone in the opposite direction? Is there anything about the site's design that might inspuire you to use it more than other search algorithms?
    - Clean interface
    - Yahoo, etc. want you to say on the page due to different buisness model.
    - No distraction.
    - Autocomplete on Google is very well anticipated.
    - Google doesn't limit searches.
    - Shopping: the quick suggestions feature.
        - doesn't "annoy" with all of the things to look at.
- If we think about Google versus yahoo, is there a certain idea of trust behind it? Does it tell us something that makes us think it's more reliable.