---
title: Surveillance & Dataveillance
author: Brett Petch
date: 2020-03-10 09:30:00
layout: category-post
categories: 
    - week-10
    - Lecture
---

Today, we're going to talk about surveillance and dataveilance, where it was feared and now how it's been integrated into everyday life. Surveillance, something we normally associate with state control. We often think of Big Brother, in George Orwell's 1984: People would snitch if others were not abiding by regulation... Alot of this was about mass surveillance. How has surveillance extended from the state? It's not just government trying to look at this; not just because we're under the camera... 

On Thursday, Dominique Kelly is going to talk about the social credits system in China. It's not associated with the same freedoms and constraints that we have here, but is often associated with data surveillance.

You will likely see connections between O'Neil reading and this week, but it will not be the focus. 

## Question
What did you think about *The Circle*? How did it present issues of surveillance and big data? Do you think it's a plausable narrative?
- Going transparent -- broadcasting every moment of your day, presented as a fun thing. Always tried to make surveillance about being something good. 

To build on this, it's addresssing are we already in this dystopia that we fear? are we in a mass surveillance society? It's in many ways trying to say that this movie is an abstracted version of today: it's almost a reverse dystopia -- what have we already created? I chose this movie to talk about privacy, dataveillance, etc. It challenges the state government. It's something done by corporations, and it's all brought into a network of surveillance; as a model of total transparency. By having this completely open world, everything will be fair, etc. The whole individual loses itself in the mass. Let's first look at this.

## Clearview AI

<iframe style="width: 55vw; height: 45vh;" src="https://www.youtube-nocookie.com/embed/ui1LaZpWHbY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

It scrapes all data from social media profiles, then look at the different people they can find with this: Used in different police systems in both Canada and the United States. This has also been employed by investors / celeberties. Aston Kutcher has talked about how he has also used it, and how does it relate to us? [London Police have also used it](https://www.cbc.ca/news/canada/london/london-ontario-police-clearview-ai-digital-surveillance-1.5485139), but have [been unclear if they have or have not used this technology](https://lfpress.com/news/local-news/london-police-admit-some-officers-used-clearview-controversial-facial-recognition-software). The ultimate goal of this is to release it to the public. If this was a public technology, there would be alot of murder: this would be like the new dating app essentially, you meet someone in public, take a photo, try to message them.

The most alarming part of this is that you put yourself into this, where your own naivety...

## Dataveillance
The systematic use of personal data systems in the investigation or monitoring of the actions or communications of one or more persons, this could be something like cellphone data, and tracking ideas about you based on geo-location, your social networking sites, etc. As we've been talking about, in terms of the way that data is used to categorize and quantify who we are. Governments and corporations use dataveillance to gather, store and analyze the tremendous amount of data we produce online. With apps like Clearview AI, or any other kind of social media, we can make assumptions based on this data. It's about taking this data and linking it to a specific type of person. Collecting data and organizing people into different categories. Linking to specific characteristics, or identities we have. 

### Case: Stanford Metadata Study
For instance, a study done by a group of Stanford Computer Scientists, they were curious about what they could find out about people through their metadata. They wouldn't have access to what you said on your phone, who did you talk to, how long? They wouldn't look at photos, but rather where you took photos. Based on this, they were able to identify someone who had a multiple sclerosis sufferer, a heart attack victim, someone that owned semi-automatic weapons, someone that grew marijuana at home, and someone who had an abortion. If someone were to call a gun store, they likely own a gun.

### Case: Credit Scores
Should i trust this person with credit? Comapnies use data research to categorize how people like you have acted in the past in order to determine credit scores? Use proxy measures such as postal code, age, gender, as well as digital data such as personality type. O'Neil: companies uses data research to categorize how "people like you" have acted inthe past in order to determine credit scores. Use proxy measures such as postal code, age, gender, as well as digital data such as postal code, age, gender, as well as digital data such as personality type. People could be risky, reckless, or likely to seek a better price.

### Case: Google Street View
Sincei ts been released, Google Street View has been subject to many surveillance and privacy concerns. Stanford researchers (including Google's Chief Scientist) found that they could predict income, race, and voting patterns using photos of the make, model and year of cars. 

Dataveillance increasingly relies on the ties between corporate and government suveillance: Clearview AI, predictive policing. We purchase our own surveillance technologies, like Baby cams, Amazon Ring Doorbels, etc. 

> Are we completely acclimatized to surveillance?

Why is it that we don't react? why is it that we're apathetic to surveillance. Maybe one way that surveillance exists differently that

> "Once perceived as a peripheral aspect of life, limited to recognizable suspects or persons-of-interest, surveillance has become central to social experience, both as a serious security issue and as a playful part of mediated relationships. In the mid 20th c. many thought of the government monitoring as 'state of surveillance'...

There are two models of surveillance

## Surveillance Types
### Panopticon
a model of surveillance in which the government employs techniques to monitor, supervise, and ultimately modify the behaviour of citizens... It uses obvious surveillance and encourages self-discipline and self-regulation.

Many physical spaces use panoptic designs as ways to internalize authority through self-regulation. For example, can this classroom be understood as panoptic?

### Cryptopticon
The surveillance of the individual through many forms of surveilllance, resulting in an inscrutable information ecosystem of massive corporate and state surveillance, unlike the panopticon: it ois not obvious or overt. This could be surveillance by Google, Facebook and government. Cryptopticon is used in digital spaces, providing a confusing mix of corporate, governmental, and social surveillance. It can track location, photos and personal data. Unlike the panopticon, the cryptopticon encourages both elements of freedom and self-regulation through digital measures to monitor and track individuals. Individuals regulate their behaviour, but are also unclear about where it is coming from, or how being used.

Eg: Cellphone: as opposed ot a prison tower, cell phones offer freedoms to do what we want, and even to surveil others. Yet they also subject us to increasing amounts of data mining, tracking and recording. Likewise, social networking provide us with freedoms to be ourselves, et also to attempt to encourage us to be our best self. 

There are three ways which we have normalized surveillance:

1. Fear
Alot of these issues are based in 9/11 and the "war on terror", wherein most people are OK with surveillance, something like 80% of people are ok with surveillance. How would you feel if police were to use Clearview AI. Most individuals are ok with surveillance to detect crime.

2. Familiarity
It has become a familiar routine of society, we take on some of these things out of convenience like a loyalty: money back, points we can use. It's also an element of convenience that becomes part of our lives. 

3. Fun and Interactivity
It's not just restraining, but also invites participation through user-generated content. It's often a reason why we could become complicit in it. There is an element that isn't completely a mode of self-discipline. For example, it could be something like a face filter or something that is fun for us because it creates and fosters relationships, connects to friends doing similar things, etc. Many of these apps become issues because they can be used for different facial recognition technologies. 

As a result of this, we often take on much of the surveillance ourselves by subjecting ourselves to self-monitoring apps that record, track and transmit our data. If we were to use a fitbit, measure my heartrate, my running app, etc. we often use these different running apps because we want to better ourselves. 

And one other thing that crops up in turn of this, one of the interesting things is that the idea of privacy is something that is more exensive. It's almost as if this is only for wealthy individuals, where car insurance companies will have a driving monitors for you. The thinking behind this is that most accidents happen after midnight, do you travel in certain locations, speed, braking, etc. This becomes somewhat mandatory, where privacy turns into a luxury for the wealthy, Apple has been criticized for this. 

To end, Surveillance is also normalized by being integrated into routine parts of society such as through social media, surveillance as a form of connection and monitoring. The privvacy paradox individuals freely give up privacy.